---
title:  "[Paper Review] Matrix Compression via Randomized Low Rank and Low Precision Factorization"
excerpt: "[Paper Review] Matrix Compression via Randomized Low Rank and Low Precision Factorization"
categories: [Paper]
tags: [low rank, compression, neurips, paper review]

toc: true
toc_sticky: true
 
date: 2024-01-01
last_modified_at: 2024-01-01 
---
## Info
2023 NeurIPS에서 발표된 논문.
Low Rank Low Precision 알고리즘을 통해 모델, 데이터셋을 효과적으로 압축

## Introduction


## Proposed Algorithm

### Uniformly Dithered Quantizer
이 논문의 알고리즘에 사용되는 양자화 방식이다.
자세한 설명

### Propoed Algorithm : LPLR
1. Direct SVD Qaunt
2. 최적화 문제의 제시
3. LPLR 알고리즘
4. 알고리즘의 이점
5. 가우시안 행렬의 선택

## Approximation Error Analysis

## Numerical Simulations

## Conclusions

## Summary
